{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PyPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Author: Huyen, Chip;\n",
      "/CreationDate: D:20220517135306Z\n",
      "/Creator: AH CSS Formatter V7.1 MR2 for Linux64 : 7.1.3.50324 (2021-04-26T09:47+09)\n",
      "/ModDate: D:20220517104004-04'00'\n",
      "/Producer: Antenna House PDF Output Library 7.1.1639\n",
      "/Title: Designing Machine Learning Systems\n",
      "/EBX_PUBLISHER: O'Reilly Media, Incorporated\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def extract_pdf_metadata(pdf_path):\n",
    "    # Open the PDF file\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        \n",
    "        # Extract document information (metadata)\n",
    "        metadata = reader.metadata\n",
    "        \n",
    "        # Convert metadata to a dictionary\n",
    "        metadata_dict = {}\n",
    "        for key, value in metadata.items():\n",
    "            metadata_dict[key] = value\n",
    "\n",
    "    return metadata_dict\n",
    "\n",
    "# Example usage\n",
    "pdf_path = r\"D:\\Buku Pembelajaran Artificial Intelligence\\Chip Huyen - Designing Machine Learning Systems_ An Iterative Process for Production-Ready Applications-O'Reilly Media (2022).pdf\"\n",
    "metadata = extract_pdf_metadata(pdf_path)\n",
    "for key, value in metadata.items():\n",
    "    print(f'{key}: {value}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "format: PDF 1.6\n",
      "title: Designing Machine Learning Systems\n",
      "author: Huyen, Chip;\n",
      "subject: \n",
      "keywords: \n",
      "creator: AH CSS Formatter V7.1 MR2 for Linux64 : 7.1.3.50324 (2021-04-26T09:47+09)\n",
      "producer: Antenna House PDF Output Library 7.1.1639\n",
      "creationDate: D:20220517135306Z\n",
      "modDate: D:20220517104004-04'00'\n",
      "trapped: \n",
      "encryption: None\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_pdf_metadata(pdf_path):\n",
    "    # Open the PDF file\n",
    "    document = fitz.open(pdf_path)\n",
    "    \n",
    "    # Extract document information (metadata)\n",
    "    metadata = document.metadata\n",
    "    \n",
    "    # Close the document\n",
    "    document.close()\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# Example usage\n",
    "pdf_path = r\"D:\\Buku Pembelajaran Artificial Intelligence\\Chip Huyen - Designing Machine Learning Systems_ An Iterative Process for Production-Ready Applications-O'Reilly Media (2022).pdf\"\n",
    "metadata = extract_pdf_metadata(pdf_path)\n",
    "for key, value in metadata.items():\n",
    "    print(f'{key}: {value}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDFMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Huyen, Chip;\n",
      "CreationDate: D:20220517135306Z\n",
      "Creator: AH CSS Formatter V7.1 MR2 for Linux64 : 7.1.3.50324 (2021-04-26T09:47+09)\n",
      "ModDate: D:20220517104004-04'00'\n",
      "Producer: Antenna House PDF Output Library 7.1.1639\n",
      "Title: Designing Machine Learning Systems\n",
      "EBX_PUBLISHER: O'Reilly Media, Incorporated\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "\n",
    "def extract_pdf_metadata(pdf_path):\n",
    "    # Open the PDF file\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        parser = PDFParser(file)\n",
    "        document = PDFDocument(parser)\n",
    "        \n",
    "        # Extract document information (metadata)\n",
    "        metadata = document.info[0]  # List of metadata dictionaries, usually containing one dictionary\n",
    "\n",
    "        # Convert metadata to a regular dictionary and decode bytes to strings\n",
    "        metadata_dict = {key: value.decode('utf-8') if isinstance(value, bytes) else value \n",
    "                         for key, value in metadata.items()}\n",
    "\n",
    "    return metadata_dict\n",
    "\n",
    "# Example usage\n",
    "pdf_path = r\"D:\\Buku Pembelajaran Artificial Intelligence\\Chip Huyen - Designing Machine Learning Systems_ An Iterative Process for Production-Ready Applications-O'Reilly Media (2022).pdf\"\n",
    "metadata = extract_pdf_metadata(pdf_path)\n",
    "for key, value in metadata.items():\n",
    "    print(f'{key}: {value}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse to Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Introduction Machine Learning': ['pengenalan konsep machine learning', 'Pembelajaran lanjut tentang machine learning'], 'Topic 2': ['Sub topic 1 from topic 2', 'Sub topic 2 from topic 2'], 'Topic 3': ['Sub topic 1 from topic 3', 'Sub topic 2 from topic 3'], 'Topic 4': ['sub topik 4']}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"\"\"\n",
    "1. Introduction Machine Learning \n",
    "   * pengenalan konsep machine learning\n",
    "   * Pembelajaran lanjut tentang machine learning\n",
    "2. Topic 2\n",
    "   * Sub topic 1 from topic 2\n",
    "   * Sub topic 2 from topic 2\n",
    "3. Topic 3\n",
    "   * Sub topic 1 from topic 3\n",
    "   * Sub topic 2 from topic 3\n",
    "4. Topic 4\n",
    "   * sub topik 4   \n",
    "\"\"\"\n",
    "\n",
    "def parse_text_to_dict(text):\n",
    "    topics = {}\n",
    "    lines = text.strip().split('\\n')\n",
    "    current_topic = None\n",
    "    \n",
    "    topic_pattern = re.compile(r'^\\d+\\.\\s+(.*)$')\n",
    "    sub_topic_pattern = re.compile(r'^\\*\\s+(.*)$')\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if topic_pattern.match(line):\n",
    "            current_topic = topic_pattern.match(line).group(1)\n",
    "            topics[current_topic] = []\n",
    "        elif sub_topic_pattern.match(line):\n",
    "            sub_topic = sub_topic_pattern.match(line).group(1)\n",
    "            if current_topic:\n",
    "                topics[current_topic].append(sub_topic)\n",
    "    \n",
    "    return topics\n",
    "\n",
    "topics = parse_text_to_dict(text)\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crew AI PDF Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting batches in chromadb: 100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n",
      "2024-08-07 15:21:43,735 - 10700 - __init__.py-__init__:531 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo accomplish the task of searching for the term 'AI advancements' within the provided PDF document, I need to use the \"Search a PDF's content\" tool. My next step is to perform the search and review the results.\n",
      "\n",
      "Action: Search a PDF's content\n",
      "Action Input: {\"query\": \"AI advancements\"}\u001b[0m\u001b[95m \n",
      "\n",
      "Relevant Content:\n",
      "real world , Deloitte, 2017. 4 The state of AI in 2020 , McKinsey, 2020.\n",
      "\n",
      "products and technologies.\n",
      "\n",
      "Executive summary Across industries, DevOps and DataOps have been widely adopted as methodologies to improve quality and re - duce the time to market of software engineering and data engineering initiatives. With the rapid growth in machine learning (ML) systems, similar approaches need to be developed in the context of ML engineering, which handle the unique complexities of the practical applications of ML. This is the domain of MLOps. MLOps is a set of standard - ized processes and technology capabilities for building, deploying, and operationalizing ML systems rapidly and reliably.] We previously published Google Cloud’s AI Adoption Framework to provide guidance for technology leaders who want to build an effective artificial intelligence (AI) capability in order to transform their business. That framework covers AI challenges around people, data, technology, and process, structured in six different themes: learn, lead, access, secure, scale, and automate . The current document\n",
      "\u001b[00m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now can give a great answer\n",
      "Final Answer: Relevant Content:\n",
      "real world , Deloitte, 2017. 4 The state of AI in 2020 , McKinsey, 2020.\n",
      "\n",
      "products and technologies.\n",
      "\n",
      "Executive summary Across industries, DevOps and DataOps have been widely adopted as methodologies to improve quality and re - duce the time to market of software engineering and data engineering initiatives. With the rapid growth in machine learning (ML) systems, similar approaches need to be developed in the context of ML engineering, which handle the unique complexities of the practical applications of ML. This is the domain of MLOps. MLOps is a set of standard - ized processes and technology capabilities for building, deploying, and operationalizing ML systems rapidly and reliably.] We previously published Google Cloud’s AI Adoption Framework to provide guidance for technology leaders who want to build an effective artificial intelligence (AI) capability in order to transform their business. That framework covers AI challenges around people, data, technology, and process, structured in six different themes: learn, lead, access, secure, scale, and automate . The current document\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Relevant Content:\n",
      "real world , Deloitte, 2017. 4 The state of AI in 2020 , McKinsey, 2020.\n",
      "\n",
      "products and technologies.\n",
      "\n",
      "Executive summary Across industries, DevOps and DataOps have been widely adopted as methodologies to improve quality and re - duce the time to market of software engineering and data engineering initiatives. With the rapid growth in machine learning (ML) systems, similar approaches need to be developed in the context of ML engineering, which handle the unique complexities of the practical applications of ML. This is the domain of MLOps. MLOps is a set of standard - ized processes and technology capabilities for building, deploying, and operationalizing ML systems rapidly and reliably.] We previously published Google Cloud’s AI Adoption Framework to provide guidance for technology leaders who want to build an effective artificial intelligence (AI) capability in order to transform their business. That framework covers AI challenges around people, data, technology, and process, structured in six different themes: learn, lead, access, secure, scale, and automate . The current document\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai_tools import PDFSearchTool\n",
    "\n",
    "# Set up environment variables (Replace with your actual keys)\n",
    "# os.environ[\"SERPER_API_KEY\"] = \"Your Serper API Key\"\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"Your OpenAI API Key\"\n",
    "\n",
    "from crewai_tools import PDFSearchTool\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the tool with a specific PDF path for exclusive search within that document\n",
    "tool = PDFSearchTool(pdf=r'D:\\Project Multimedika\\Documents-Summarizer-and-Question-Makers\\resources\\file.pdf')\n",
    "\n",
    "# Create the agent\n",
    "pdf_researcher = Agent(\n",
    "    role='PDF Researcher',\n",
    "    goal='Extract specific information from a PDF document.',\n",
    "    verbose=True,\n",
    "    memory=True,\n",
    "    backstory=(\n",
    "        \"You have a keen eye for detail and excel at finding specific information \"\n",
    "        \"within lengthy documents. Your expertise is in navigating and extracting \"\n",
    "        \"relevant data from PDFs.\"\n",
    "    ),\n",
    "    tools=[tool]\n",
    ")\n",
    "\n",
    "# Create the task\n",
    "pdf_search_task = Task(\n",
    "    description=(\n",
    "        \"Search for the term 'AI advancements' within the provided PDF document. \"\n",
    "        \"Extract and summarize the sections where this term appears. \"\n",
    "        \"Your final output should be a concise summary of these sections.\"\n",
    "    ),\n",
    "    expected_output='A summary of the sections containing the term \"AI advancements\".',\n",
    "    tools=[tool],\n",
    "    agent=pdf_researcher\n",
    ")\n",
    "\n",
    "# Form the crew\n",
    "crew = Crew(\n",
    "    agents=[pdf_researcher],\n",
    "    tasks=[pdf_search_task],\n",
    "    process=Process.sequential\n",
    ")\n",
    "\n",
    "# Kick off the process\n",
    "result = crew.kickoff()\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ExtractorPDF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
